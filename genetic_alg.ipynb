{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# # fetch dataset \n",
    "# optical_recognition_of_handwritten_digits = fetch_ucirepo(id=80) \n",
    "  \n",
    "# # data (as pandas dataframes) \n",
    "# X = optical_recognition_of_handwritten_digits.data.features \n",
    "# y = optical_recognition_of_handwritten_digits.data.targets \n",
    "  \n",
    "# # metadata \n",
    "# print(optical_recognition_of_handwritten_digits.metadata) \n",
    "\n",
    "# # variable information \n",
    "# print(optical_recognition_of_handwritten_digits.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y= y.to_numpy()\n",
    "# y =y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "# svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_classifier = xgb.XGBClassifier()\n",
    "# xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_pop_fitness(pop, X_train, y_train, X_test, y_test):\n",
    "    fitness = []\n",
    "    for i in range(len(pop)):\n",
    "        columns = np.unique(pop[i])\n",
    "        \n",
    "        X_train_ind = X_train.iloc[:,columns]\n",
    "        rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf_classifier.fit(X_train_ind, y_train)\n",
    "\n",
    "        y_pred = rf_classifier.predict(X_test.iloc[:,columns])\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        fitness.append(accuracy)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def fit_svm(pop, X_train, y_train, X_test, y_test):\n",
    "    fitness = []\n",
    "    for i in range(len(pop)):\n",
    "        columns = np.unique(pop[i])\n",
    "        \n",
    "        X_train_ind = X_train.iloc[:, columns]\n",
    "        svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "        svm_classifier.fit(X_train_ind, y_train)\n",
    "\n",
    "        y_pred = svm_classifier.predict(X_test.iloc[:, columns])\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        fitness.append(accuracy)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def fit_xgboost(pop, X_train, y_train, X_test, y_test):\n",
    "    fitness = []\n",
    "    for i in range(len(pop)):\n",
    "        columns = np.unique(pop[i])\n",
    "        \n",
    "        X_train_ind = X_train.iloc[:, columns]\n",
    "        xgb_classifier = xgb.XGBClassifier()\n",
    "        xgb_classifier.fit(X_train_ind, y_train)\n",
    "\n",
    "        y_pred = xgb_classifier.predict(X_test.iloc[:, columns])\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        fitness.append(accuracy)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def select_mating_pool(pop, fitness, num_parents):\n",
    "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
    "    parents = np.empty((num_parents, pop.shape[1]))\n",
    "    for parent_num in range(num_parents):\n",
    "        max_fitness_idx = np.where(fitness == np.max(fitness))\n",
    "        max_fitness_idx = max_fitness_idx[0][0]\n",
    "        parents[parent_num, :] = pop[max_fitness_idx, :]\n",
    "        fitness[max_fitness_idx] = -1\n",
    "    return parents\n",
    "\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = np.empty(offspring_size)\n",
    "\n",
    "    for k in range(offspring_size[0]):\n",
    "        # Always perform one-point crossover.\n",
    "        crossover_point = np.random.randint(1, parents.shape[1])\n",
    "        parent1_idx = k % parents.shape[0]\n",
    "        parent2_idx = (k + 1) % parents.shape[0]\n",
    "        offspring[k, :crossover_point] = parents[parent1_idx, :crossover_point]\n",
    "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "\n",
    "    return offspring\n",
    "\n",
    "def mutation(offspring_crossover):\n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    for idx in range(offspring_crossover.shape[0]):\n",
    "        # The random value to be added to the gene.\n",
    "        random_value = np.random.choice([-1, 0, 1], 1)\n",
    "        offspring_crossover[idx, 4] = offspring_crossover[idx, 4] + random_value\n",
    "    return offspring_crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[514 445 313 495 376 440 221 731 184 632 613 209 489 308 261 106 635 623\n",
      "  431 287 277 509 645 476 205 506   5 586]\n",
      " [542 436 541 527 398 171 560 379 575 292 173 475 547 338 166 577 402 182\n",
      "  413 472 566 623 783 373 383 460 415 471]\n",
      " [387 596  82 501 507 267 553 529 316 297 178 348 319 549 466 538 328 335\n",
      "  319 380 546 268 783 438 434 737 366 597]\n",
      " [329 649 434  96 145 525 445 437 773 486 385 546 350 475 461 331 310 513\n",
      "  529 304   7 539 603 321 194 421 637 399]\n",
      " [359 442 156 439 369 533 308 399 385 327 301 393 456 520 596 314 415 457\n",
      "  267 283 415 134 742 379 315 461 528 356]\n",
      " [774 328 371 561 125 425 288 400 457 379 319 492 411 289 247 325 352 614\n",
      "  409 385 572 554 462 401 287 347 397 372]\n",
      " [348 470 507 469 334 168 239   0 426   0 174 423 437 422 489 201 109 145\n",
      "  496 233 359 558 284 432 334 214 396 548]\n",
      " [306 386 571 404 465 244 375 232 358 290 458 295 615 320 573 396  60 366\n",
      "  458 642 761 602 135 365 210 361 355 269]\n",
      " [446 188 615 617 300 385 301 460 424 363 584 284 358 432 407 290 306 283\n",
      "  406 504 502 438  51 356 418 213 498 293]\n",
      " [188 506 214 552 184 442 423 616 218 441 304 286 379 465 304 410 444 585\n",
      "  371 370 213 259 416 760 320  88 518 404]\n",
      " [416 223 515 384 365 619 300 211 461  94 545 515 367 505 210 399 587 276\n",
      "  487 585 347  88 533 491 489 169 478 408]\n",
      " [339 554 404 155 345 469 410 575 656 471 249 223 264 466 595 404 560 463\n",
      "  368 484 516 273 158 655 151 464 603 625]\n",
      " [443 241  12 479 375 598 631 597 481 216 327 131 127 422 556 317 486 267\n",
      "  658 431 462 306 490 483 474 533 607 398]\n",
      " [473 307 531 448 662 461 670 374 585 667 744 152 410 700 160 328 263 558\n",
      "  409 287 474 400 419 524 206 393 244 329]\n",
      " [436 339 492 431 413 487 609 502 244 303 536 141 502 226 171 219 687 464\n",
      "  698 344 522 267 502 357 203 599 295 265]\n",
      " [294 570 600 539 454 618 446 381 471 366 313 501 303 360 445 522 476 341\n",
      "  263 474 540 579 620 291 383 384 374 574]]\n"
     ]
    }
   ],
   "source": [
    "col_len = 28\n",
    "\n",
    "sol_per_pop = 16\n",
    "num_parents_mating = 8\n",
    "\n",
    "pop_size = (sol_per_pop,col_len)\n",
    "\n",
    "max_value = 783 \n",
    "std_dev = 150\n",
    "mean = max_value / 2\n",
    "\n",
    "new_population = np.random.normal(mean, std_dev, pop_size).astype(int)\n",
    "\n",
    "new_population[new_population > max_value] = max_value\n",
    "new_population[new_population < 0] = 0\n",
    "\n",
    "print(new_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train = X_train[:10000]\n",
    "X_test = X_test[:3000]\n",
    "y_train = y_train[:10000]\n",
    "y_test = y_test[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7606666666666667, 0.7906666666666666, 0.8053333333333333, 0.7316666666666667, 0.7493333333333333, 0.798, 0.681, 0.7986666666666666, 0.7153333333333334, 0.7423333333333333, 0.7133333333333334, 0.8116666666666666, 0.8223333333333334, 0.7373333333333333, 0.758, 0.7416666666666667]\n",
      "Generation :  0\n",
      "\n",
      "[0.8223333333333334, 0.8116666666666666, 0.8053333333333333, 0.7986666666666666, 0.798, 0.7906666666666666, 0.7606666666666667, 0.758, 0.8216666666666667, 0.813, 0.8236666666666667, 0.8073333333333333, 0.792, 0.7166666666666667, 0.7883333333333333, 0.7043333333333334]\n",
      "[0.8236666666666667, 0.8223333333333334, 0.8216666666666667, 0.813, 0.8116666666666666, 0.8073333333333333, 0.8053333333333333, 0.7986666666666666, 0.8026666666666666, 0.8363333333333334, 0.8116666666666666, 0.815, 0.8053333333333333, 0.8113333333333334, 0.8206666666666667, 0.8003333333333333]\n",
      "[0.8363333333333334, 0.8236666666666667, 0.8223333333333334, 0.8216666666666667, 0.8206666666666667, 0.815, 0.813, 0.8116666666666666, 0.779, 0.784, 0.8163333333333334, 0.804, 0.828, 0.8146666666666667, 0.8043333333333333, 0.8116666666666666]\n",
      "[0.8363333333333334, 0.828, 0.8236666666666667, 0.8223333333333334, 0.8216666666666667, 0.8206666666666667, 0.8163333333333334, 0.815, 0.8206666666666667, 0.7683333333333333, 0.8086666666666666, 0.8413333333333334, 0.814, 0.7926666666666666, 0.81, 0.835]\n",
      "[0.8413333333333334, 0.8363333333333334, 0.835, 0.828, 0.8236666666666667, 0.8223333333333334, 0.8216666666666667, 0.8206666666666667, 0.8413333333333334, 0.8403333333333334, 0.8233333333333334, 0.799, 0.809, 0.821, 0.8116666666666666, 0.8493333333333334]\n",
      "[0.8493333333333334, 0.8413333333333334, 0.8413333333333334, 0.8403333333333334, 0.8363333333333334, 0.835, 0.828, 0.8236666666666667, 0.8203333333333334, 0.8443333333333334, 0.8216666666666667, 0.8363333333333334, 0.8403333333333334, 0.8356666666666667, 0.7323333333333333, 0.816]\n",
      "[0.8493333333333334, 0.8443333333333334, 0.8413333333333334, 0.8413333333333334, 0.8403333333333334, 0.8403333333333334, 0.8363333333333334, 0.8363333333333334, 0.8463333333333334, 0.8443333333333334, 0.8413333333333334, 0.8403333333333334, 0.8403333333333334, 0.8403333333333334, 0.8363333333333334, 0.8403333333333334]\n",
      "[0.8493333333333334, 0.8463333333333334, 0.8443333333333334, 0.8443333333333334, 0.8413333333333334, 0.8413333333333334, 0.8413333333333334, 0.8403333333333334, 0.8493333333333334, 0.8463333333333334, 0.8443333333333334, 0.8443333333333334, 0.8423333333333334, 0.8443333333333334, 0.8423333333333334, 0.8563333333333333]\n",
      "[0.8563333333333333, 0.8493333333333334, 0.8493333333333334, 0.8463333333333334, 0.8463333333333334, 0.8443333333333334, 0.8443333333333334, 0.8443333333333334, 0.8566666666666667, 0.8446666666666667, 0.8493333333333334, 0.8463333333333334, 0.83, 0.8443333333333334, 0.849, 0.8563333333333333]\n"
     ]
    }
   ],
   "source": [
    "num_generations = 10\n",
    "for generation in range(num_generations):\n",
    "    # Measing the fitness of each chromosome in the population.\n",
    "    fitness = cal_pop_fitness(new_population, X_train,y_train,X_test,y_test)\n",
    "\n",
    "    print(fitness)\n",
    "\n",
    "    # Selecting the best parents in the population for mating.\n",
    "    parents = select_mating_pool(new_population, fitness, \n",
    "                                      num_parents_mating)\n",
    "    \n",
    "    # print(parents)\n",
    "\n",
    "    # Generating next generation using crossover.\n",
    "    offspring_crossover = crossover(parents,\n",
    "                                       offspring_size=(pop_size[0]-parents.shape[0], col_len))\n",
    "\n",
    "\n",
    "    # Adding some variations to the offsrping using mutation.\n",
    "    offspring_mutation = mutation(offspring_crossover)\n",
    "\n",
    "    # print(offspring_mutation)\n",
    "\n",
    "    # Creating the new population based on the parents and offspring.\n",
    "    new_population[0:parents.shape[0], :] = parents\n",
    "    new_population[parents.shape[0]:, :] = offspring_mutation  # should be offspring_mutation\n",
    "\n",
    "    # The best result in the current iteration.\n",
    "    if generation%10 ==0:\n",
    "        print(\"Generation : \", generation)\n",
    "        # print(offspring_crossover)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution fitness :  0.8566666666666667\n"
     ]
    }
   ],
   "source": [
    "# Getting the best solution after iterating finishing all generations.\n",
    "#At first, the fitness is calculated for each solution in the final generation.\n",
    "fitness = cal_pop_fitness(new_population, X_train, y_train, X_test,y_test)\n",
    "# Then return the index of that solution corresponding to the best fitness.\n",
    "best_match_idx = np.where(fitness == np.max(fitness))\n",
    "\n",
    "# print(\"Best solution : \", new_population[best_match_idx, :])\n",
    "print(\"Best solution fitness : \", fitness[best_match_idx[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution :  [[[443 241  12 501 505 267 553 529 316 297 178 348 319 549 466 538 486\n",
      "   267 658 431 462 273 158 655 151 464 603 625]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best solution : \", new_population[best_match_idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9667619047619047\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = new_population[best_match_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([443, 241,  12, 501, 505, 267, 553, 529, 316, 297, 178, 348, 319,\n",
       "       549, 466, 538, 486, 267, 658, 431, 462, 273, 158, 655, 151, 464,\n",
       "       603, 625])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8838571428571429\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train.iloc[:,feat[0][0]], y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test.iloc[:,feat[0][0]])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7365714285714285\n"
     ]
    }
   ],
   "source": [
    "new_population = np.random.randint(0, 783, size=28)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train.iloc[:,new_population], y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test.iloc[:,new_population])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([395, 475, 636, 353, 577, 507, 244, 378, 711, 368, 242, 221, 458,\n",
       "       517, 273, 643,  53, 141,  44, 479,  21, 582,  70, 305, 526, 178,\n",
       "       463, 747])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.32528814895085"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9505714285714286/0.96676190476190470 * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

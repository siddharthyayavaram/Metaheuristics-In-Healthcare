{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, parser='auto')\n",
    "X, y = mnist.data, mnist.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_rf_classifier(particle, X_train, X_test, y_train, y_test):\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "    rf_classifier.fit(X_train.iloc[:, particle], y_train)\n",
    "\n",
    "    y_pred = rf_classifier.predict(X_test.iloc[:, particle])\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differential_evolution(X_train, X_test, y_train, y_test, pop_size, totalfeat, max_iterations):\n",
    "    # Initialization\n",
    "    num_particles, col_len = pop_size\n",
    "    max_value = 783\n",
    "    std_dev = 150\n",
    "    mean = max_value / 2\n",
    "\n",
    "    # Initialize population using normal distribution\n",
    "    population = np.random.normal(mean, std_dev, (num_particles, col_len)).astype(int)\n",
    "    population[population > max_value] = max_value\n",
    "    population[population < 0] = 0\n",
    "\n",
    "    for iteration in tqdm(range(max_iterations)):\n",
    "        for i in range(num_particles):\n",
    "            # Select three random individuals\n",
    "            candidates = np.random.choice(num_particles, 3, replace=False)\n",
    "            a, b, c = population[candidates]\n",
    "\n",
    "            # Mutation\n",
    "            mutant = np.clip(a + 0.5 * (b - c), 0, max_value).astype(int)\n",
    "\n",
    "            # Crossover\n",
    "            crossover_mask = np.random.rand(col_len) < 0.7\n",
    "            trial = np.where(crossover_mask, mutant, population[i])\n",
    "\n",
    "            # Selection\n",
    "            if fitness_rf_classifier(trial, X_train, X_test, y_train, y_test) > fitness_rf_classifier(population[i], X_train, X_test, y_train, y_test):\n",
    "                population[i] = trial\n",
    "\n",
    "    # Find the best individual\n",
    "    best_individual = population[np.argmax([fitness_rf_classifier(ind, X_train, X_test, y_train, y_test) for ind in population])]\n",
    "    \n",
    "    return best_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:05<00:00, 60.59s/it]\n"
     ]
    }
   ],
   "source": [
    "num_features = 28  # Change this according to your actual number of features\n",
    "pop_size = 16\n",
    "max_iter = 10\n",
    "\n",
    "num_particles = 16\n",
    "col_len = 28\n",
    "max_value = 783\n",
    "\n",
    "best_solution = differential_evolution(X_train, X_test, y_train, y_test, (num_particles, col_len), max_value, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[459 371 409 514 305 262 295 439 326 291 588 365 307 290 302 254 515 324\n",
      " 219 348 290 149 119 483 406 466 358 213]\n"
     ]
    }
   ],
   "source": [
    "print(best_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8682857142857143\n"
     ]
    }
   ],
   "source": [
    "X_train_subset = X_train.iloc[:, best_solution]\n",
    "X_test_subset = X_test.iloc[:, best_solution]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_subset, y_train)\n",
    "y_pred = clf.predict(X_test_subset)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 28  # Change this according to your actual number of features\n",
    "max_iter = 10\n",
    "\n",
    "num_particles = 16\n",
    "col_len = 28\n",
    "max_value = 783\n",
    "\n",
    "max_value = 783\n",
    "std_dev = 150\n",
    "mean = max_value / 2\n",
    "\n",
    "# Initialize population using normal distribution\n",
    "population = np.random.normal(mean, std_dev, (num_particles, col_len)).astype(int)\n",
    "population[population > max_value] = max_value\n",
    "population[population < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([429, 200, 515, 353, 438, 320, 359, 242, 409, 517, 566, 170, 400,\n",
       "       431, 482, 509, 594, 343, 672, 407, 356, 278, 570, 526, 305, 436,\n",
       "       521, 386])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset = X_train.iloc[:, population[0]]\n",
    "X_test_subset = X_test.iloc[:, population[0]]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_subset, y_train)\n",
    "y_pred = clf.predict(X_test_subset)\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6915238095238095\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8682857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      2058\n",
      "           1       0.93      0.97      0.95      2364\n",
      "           2       0.83      0.83      0.83      2133\n",
      "           3       0.87      0.86      0.86      2176\n",
      "           4       0.81      0.80      0.81      1936\n",
      "           5       0.88      0.87      0.88      1915\n",
      "           6       0.89      0.93      0.91      2088\n",
      "           7       0.89      0.84      0.86      2248\n",
      "           8       0.85      0.80      0.83      1992\n",
      "           9       0.78      0.81      0.79      2090\n",
      "\n",
      "    accuracy                           0.87     21000\n",
      "   macro avg       0.87      0.87      0.87     21000\n",
      "weighted avg       0.87      0.87      0.87     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "new_population = [459 ,371 ,409 ,514 ,305 ,262 ,295, 439, 326, 291, 588 ,365 ,307, 290, 302 ,254, 515, 324,\n",
    " 219 ,348 ,290 ,149 ,119, 483, 406, 466 ,358 ,213]\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train.iloc[:,new_population], y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test.iloc[:,new_population])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

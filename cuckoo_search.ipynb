{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist.data, mnist.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_nests(num_nests, num_features):\n",
    "    return np.random.choice([0, 1], size=(num_nests, num_features), replace=True)\n",
    "\n",
    "def evaluate_nests(X_train, y_train, X_test, y_test, nests):\n",
    "    accuracies = []\n",
    "\n",
    "    for nest in nests:\n",
    "        selected_features = np.where(nest)[0]\n",
    "        X_train_selected = X_train[:, selected_features]\n",
    "        X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "        classifier = RandomForestClassifier(n_estimators=5, random_state=42)\n",
    "        classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test_selected)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return np.array(accuracies)\n",
    "\n",
    "def levy_flight(scale, size):\n",
    "    sigma_u = (np.math.gamma(1 + size) * np.sin(np.pi * size / 2)) / (np.math.gamma((1 + size) / 2) * size * 2 ** ((size - 1) / 2))\n",
    "    sigma_v = 1\n",
    "\n",
    "    u = np.random.normal(0, sigma_u, size)\n",
    "    v = np.random.normal(0, sigma_v, size)\n",
    "\n",
    "    step = u / (np.abs(v) ** (1 / size))\n",
    "\n",
    "    return scale * step\n",
    "\n",
    "def cuckoo_search_feature_selection(X_train, y_train, X_test, y_test, num_nests, num_iterations, pa, alpha):\n",
    "    num_features = X_train.shape[1]\n",
    "    nests = initialize_nests(num_nests, num_features)\n",
    "    current_best_nest = None\n",
    "    current_best_accuracy = 0.0\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        print(\"Iteration:\", iteration + 1)\n",
    "\n",
    "        # Evaluate nests\n",
    "        nest_accuracies = evaluate_nests(X_train, y_train, X_test, y_test, nests)\n",
    "        print(\"Best Accuracy in Iteration:\", np.max(nest_accuracies))\n",
    "\n",
    "        # Find the best nest\n",
    "        max_accuracy_index = np.argmax(nest_accuracies)\n",
    "        if nest_accuracies[max_accuracy_index] > current_best_accuracy:\n",
    "            current_best_nest = nests[max_accuracy_index].copy()\n",
    "            current_best_accuracy = nest_accuracies[max_accuracy_index]\n",
    "\n",
    "        # Get a new solution via Levy flight\n",
    "        new_nest_index = np.random.randint(num_nests)\n",
    "        new_nest = nests[new_nest_index].copy()\n",
    "        step_size = levy_flight(alpha, num_features)\n",
    "        new_nest = (new_nest + step_size).clip(0, 1)\n",
    "\n",
    "        # Replace the old nest with the new one based on probability pa\n",
    "        if np.random.rand() < pa:\n",
    "            nests[new_nest_index] = new_nest\n",
    "\n",
    "    # Select top num_selected_features based on the current_best_nest\n",
    "    selected_indices = np.where(current_best_nest)[0]\n",
    "    print(\"Selected Feature Indices:\", selected_indices)\n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "num_nests = 20\n",
    "num_iterations = 10\n",
    "pa = 0.25\n",
    "alpha = 1.5\n",
    "result = cuckoo_search_feature_selection(np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test), num_nests=num_nests, num_iterations=num_iterations, pa=pa, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset = X_train.iloc[:, result]\n",
    "X_test_subset = X_test.iloc[:, result]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_subset, y_train)\n",
    "y_pred = clf.predict(X_test_subset)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

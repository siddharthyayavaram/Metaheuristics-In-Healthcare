{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist.data, mnist.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_harmony_memory(num_harmonies, num_features, n_selected_features):\n",
    "    harmonies = np.zeros((num_harmonies, num_features), dtype=bool)\n",
    "    \n",
    "    for i in range(num_harmonies):\n",
    "        selected_indices = np.random.choice(num_features, n_selected_features, replace=False)\n",
    "        harmonies[i, selected_indices] = 1\n",
    "    \n",
    "    return harmonies\n",
    "\n",
    "def evaluate_harmonies(X_train, y_train, X_test, y_test, harmonies):\n",
    "    accuracies = []\n",
    "\n",
    "    for harmony in harmonies:\n",
    "        selected_features = np.where(harmony)[0]\n",
    "        X_train_selected = X_train[:, selected_features]\n",
    "        X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "        classifier = RandomForestClassifier(n_estimators=5, random_state=42)\n",
    "        classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test_selected)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return np.array(accuracies)\n",
    "\n",
    "def update_harmony_memory(harmonies, best_harmony, worst_harmony, harmony_rate, pitch_adjustment_rate):\n",
    "    for i in range(harmonies.shape[0]):\n",
    "        rand = np.random.rand(harmonies.shape[1])\n",
    "\n",
    "        # Adjust pitch\n",
    "        pitch_adjustment = np.random.rand()\n",
    "        pitch_mask = rand < pitch_adjustment_rate\n",
    "        harmonies[i, pitch_mask] = best_harmony[pitch_mask]\n",
    "\n",
    "        # Adjust value\n",
    "        value_adjustment = np.random.rand()\n",
    "        value_mask = rand < harmony_rate\n",
    "        harmonies[i, value_mask] = best_harmony[value_mask] if np.random.rand() < 0.5 else worst_harmony[value_mask]\n",
    "\n",
    "    return harmonies\n",
    "\n",
    "def harmony_search_feature_selection(X_train, y_train, X_test, y_test, num_harmonies, num_iterations, n_selected_features, harmony_rate, pitch_adjustment_rate):\n",
    "    num_features = X_train.shape[1]\n",
    "    harmonies = initialize_harmony_memory(num_harmonies, num_features, n_selected_features)\n",
    "    global_best = None\n",
    "    global_best_accuracy = 0.0\n",
    "\n",
    "    for iteration in range(1, num_iterations + 1):\n",
    "        print(\"Iteration:\", iteration)\n",
    "\n",
    "        # Evaluate harmonies\n",
    "        harmony_accuracies = evaluate_harmonies(X_train, y_train, X_test, y_test, harmonies)\n",
    "        print(\"Harmony Accuracies:\", harmony_accuracies)\n",
    "\n",
    "        # Find the index of the best harmony\n",
    "        best_harmony_index = np.argmax(harmony_accuracies)\n",
    "        # print(\"Best Harmony Index:\", best_harmony_index)\n",
    "\n",
    "        if harmony_accuracies[best_harmony_index] > global_best_accuracy:\n",
    "            global_best = harmonies[best_harmony_index].copy()\n",
    "            global_best_accuracy = harmony_accuracies[best_harmony_index]\n",
    "\n",
    "        # Update harmony memory\n",
    "        worst_harmony_index = np.argmin(harmony_accuracies)\n",
    "        harmonies = update_harmony_memory(harmonies, harmonies[best_harmony_index], harmonies[worst_harmony_index], harmony_rate, pitch_adjustment_rate)\n",
    "\n",
    "        # Stop if the desired number of features is reached\n",
    "        if np.sum(global_best) >= n_selected_features:\n",
    "            break\n",
    "\n",
    "    # Select top n_selected_features based on the global_best\n",
    "    selected_indices = np.where(global_best)[0][:n_selected_features]\n",
    "    print(\"Selected Feature Indices:\", selected_indices)\n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Harmony Accuracies: [0.62752381 0.69514286 0.60528571 0.69814286 0.439      0.68414286\n",
      " 0.65819048 0.70852381 0.62842857 0.63609524]\n",
      "Selected Feature Indices: [ 96  98 121 125 127 128 246 278 279 281 295 302 313 351 453 455 458 480\n",
      " 488 493 494 568 634 685 692 715 718 754]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "num_iterations = 10\n",
    "n_selected_features = 28\n",
    "harmony_rate = 0.7\n",
    "pitch_adjustment_rate = 0.1\n",
    "result = harmony_search_feature_selection(np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test), num_harmonies=10, num_iterations=num_iterations, n_selected_features=n_selected_features, harmony_rate=harmony_rate, pitch_adjustment_rate=pitch_adjustment_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7645238095238095\n"
     ]
    }
   ],
   "source": [
    "X_train_subset = X_train.iloc[:, result]\n",
    "X_test_subset = X_test.iloc[:, result]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_subset, y_train)\n",
    "y_pred = clf.predict(X_test_subset)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

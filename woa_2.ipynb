{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness function for RandomForestClassifier\n",
    "def fitness_rf_classifier(particle, X_train, X_test, y_train, y_test):\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "    rf_classifier.fit(X_train.iloc[:, particle], y_train)\n",
    "\n",
    "    y_pred = rf_classifier.predict(X_test.iloc[:, particle])\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whale_optimization_algorithm(pop, X_train, X_test, y_train, y_test, pop_size, totalfeat, max_iterations):\n",
    "    population = pop\n",
    "    \n",
    "    for iteration in tqdm(range(max_iterations)):\n",
    "        for i in range(pop_size):\n",
    "            a, A, C, l, p = np.random.uniform(-1, 1, 5)\n",
    "            \n",
    "            D = np.abs(C * population[int(p)].astype(int) - population[i].astype(int))\n",
    "            X_rand = population[int(l)] - A * D\n",
    "            new_solution = np.clip(X_rand, 0, totalfeat - 1).astype(int)\n",
    "            \n",
    "            fitness_current = fitness_rf_classifier(population[i], X_train, X_test, y_train, y_test)\n",
    "            fitness_new = fitness_rf_classifier(new_solution, X_train, X_test, y_train, y_test)\n",
    "            \n",
    "            if fitness_new > fitness_current:\n",
    "                population[i] = new_solution\n",
    "    \n",
    "    best_individual = population[np.argmax([fitness_rf_classifier(ind, X_train, X_test, y_train, y_test) for ind in population])]\n",
    "    return best_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assuming X_train, y_train, X_test, and y_test are already defined\n",
    "num_features = 28  # Change this according to your actual number of features\n",
    "pop_size = 16\n",
    "max_iter = 10\n",
    "\n",
    "num_particles = 16\n",
    "col_len = 28\n",
    "max_value = 783\n",
    "std_dev = 150\n",
    "mean = max_value / 2\n",
    "pop_size = (num_particles, col_len)\n",
    "\n",
    "population = np.random.normal(mean, std_dev, pop_size).astype(int)\n",
    "population[population > max_value] = max_value\n",
    "population[population < 0] = 0\n",
    "\n",
    "totalfeat = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([722, 469, 277, 565, 357, 309, 267, 355, 384, 295, 433, 268, 374,\n",
       "       245, 583, 465,  47, 345, 337,  68, 403, 623, 206, 379, 369, 617,\n",
       "       128, 368])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:41<00:00, 58.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best solution found:\n",
      "[132 240 321 301 327 408 291 220 222 432 238 284 573 147 289 409 405 381\n",
      " 483 514 307 281 601 516 459 368 271 491]\n",
      "Accuracy of best solution = 0.845643\n"
     ]
    }
   ],
   "source": [
    "# # Initialize population\n",
    "# population = np.random.randint(0, totalfeat, size=(pop_size, num_features))\n",
    "\n",
    "# Run the WOA algorithm\n",
    "best_solution = whale_optimization_algorithm(population, X_train, X_test, y_train, y_test, pop_size[0], totalfeat, max_iter)\n",
    "\n",
    "print(\"\\nBest solution found:\")\n",
    "print(best_solution)\n",
    "accuracy = fitness_rf_classifier(best_solution, X_train, X_test, y_train, y_test)\n",
    "print(\"Accuracy of best solution = %.6f\" % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

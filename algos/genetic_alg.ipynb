{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1,parser ='auto')\n",
    "X, y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_pop_fitness(pop, X_train, y_train, X_test, y_test):\n",
    "    fitness = []\n",
    "    for i in range(len(pop)):\n",
    "        columns = np.unique(pop[i])\n",
    "        \n",
    "        X_train_ind = X_train.iloc[:,columns]\n",
    "        rf_classifier = RandomForestClassifier(n_estimators=5, random_state=42)\n",
    "        rf_classifier.fit(X_train_ind, y_train)\n",
    "\n",
    "        y_pred = rf_classifier.predict(X_test.iloc[:,columns])\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        fitness.append(accuracy)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def fit_svm(pop, X_train, y_train, X_test, y_test):\n",
    "    fitness = []\n",
    "    for i in range(len(pop)):\n",
    "        columns = np.unique(pop[i])\n",
    "        \n",
    "        X_train_ind = X_train.iloc[:, columns]\n",
    "        svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "        svm_classifier.fit(X_train_ind, y_train)\n",
    "\n",
    "        y_pred = svm_classifier.predict(X_test.iloc[:, columns])\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        fitness.append(accuracy)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def fit_xgboost(pop, X_train, y_train, X_test, y_test):\n",
    "    fitness = []\n",
    "    for i in range(len(pop)):\n",
    "        columns = np.unique(pop[i])\n",
    "        \n",
    "        X_train_ind = X_train.iloc[:, columns]\n",
    "        xgb_classifier = xgb.XGBClassifier()\n",
    "        xgb_classifier.fit(X_train_ind, y_train)\n",
    "\n",
    "        y_pred = xgb_classifier.predict(X_test.iloc[:, columns])\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        fitness.append(accuracy)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def select_mating_pool(pop, fitness, num_parents):\n",
    "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
    "    parents = np.empty((num_parents, pop.shape[1]))\n",
    "    for parent_num in range(num_parents):\n",
    "        max_fitness_idx = np.where(fitness == np.max(fitness))\n",
    "        max_fitness_idx = max_fitness_idx[0][0]\n",
    "        parents[parent_num, :] = pop[max_fitness_idx, :]\n",
    "        fitness[max_fitness_idx] = -1\n",
    "    return parents\n",
    "\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = np.empty(offspring_size)\n",
    "\n",
    "    for k in range(offspring_size[0]):\n",
    "        # Always perform one-point crossover.\n",
    "        crossover_point = np.random.randint(1, parents.shape[1])\n",
    "        parent1_idx = k % parents.shape[0]\n",
    "        parent2_idx = (k + 1) % parents.shape[0]\n",
    "        offspring[k, :crossover_point] = parents[parent1_idx, :crossover_point]\n",
    "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "\n",
    "    return offspring\n",
    "\n",
    "def crossover_2(parents, offspring_size, method='two_point'):\n",
    "    offspring = np.empty(offspring_size)\n",
    "\n",
    "    for k in range(offspring_size[0]):\n",
    "        if method == 'two_point':\n",
    "            # Two-point crossover\n",
    "            crossover_points = np.sort(np.random.choice(parents.shape[1], 2, replace=False))\n",
    "            offspring[k, :crossover_points[0]] = parents[k % parents.shape[0], :crossover_points[0]]\n",
    "            offspring[k, crossover_points[0]:crossover_points[1]] = parents[(k + 1) % parents.shape[0], crossover_points[0]:crossover_points[1]]\n",
    "            offspring[k, crossover_points[1]:] = parents[k % parents.shape[0], crossover_points[1]:]\n",
    "        elif method == 'uniform':\n",
    "            # Uniform crossover\n",
    "            mask = np.random.randint(0, 2, size=parents.shape[1], dtype=bool)\n",
    "            offspring[k, mask] = parents[k % parents.shape[0], mask]\n",
    "            offspring[k, ~mask] = parents[(k + 1) % parents.shape[0], ~mask]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid crossover method. Supported methods: 'two_point', 'uniform'\")\n",
    "\n",
    "    return offspring\n",
    "\n",
    "def mutation(offspring_crossover):\n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    for idx in range(offspring_crossover.shape[0]):\n",
    "        # The random value to be added to the gene.\n",
    "        random_value = np.random.choice([-1, 0, 1], 1)\n",
    "        offspring_crossover[idx, 4] = offspring_crossover[idx, 4] + random_value\n",
    "    return offspring_crossover\n",
    "\n",
    "def enhanced_mutation(offspring_crossover, mutation_rate=0.1):\n",
    "    num_genes_to_mutate = int(offspring_crossover[0].size * mutation_rate)\n",
    "\n",
    "    for idx in range(offspring_crossover.shape[0]):\n",
    "        # Select random indices to mutate\n",
    "        mutation_indices = np.random.choice(offspring_crossover.shape[1], num_genes_to_mutate, replace=False)\n",
    "\n",
    "        # Generate random values for mutation\n",
    "        random_values = np.random.choice([-1, 0, 1], num_genes_to_mutate)\n",
    "\n",
    "        # Apply mutation to selected indices\n",
    "        offspring_crossover[idx, mutation_indices] += random_values\n",
    "\n",
    "    return offspring_crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_len = 28\n",
    "\n",
    "sol_per_pop = 32\n",
    "num_parents_mating = 8\n",
    "\n",
    "pop_size = (sol_per_pop,col_len)\n",
    "\n",
    "max_value = 783 \n",
    "std_dev = 150\n",
    "mean = max_value / 2\n",
    "\n",
    "new_population = np.random.normal(mean, std_dev, pop_size).astype(int)\n",
    "\n",
    "new_population[new_population > max_value] = max_value\n",
    "new_population[new_population < 0] = 0\n",
    "\n",
    "print(new_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train = X_train[:10000]\n",
    "X_test = X_test[:3000]\n",
    "y_train = y_train[:10000]\n",
    "y_test = y_test[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_generations = 20\n",
    "for generation in range(num_generations):\n",
    "    # Measing the fitness of each chromosome in the population.\n",
    "    fitness = cal_pop_fitness(new_population, X_train,y_train,X_test,y_test)\n",
    "\n",
    "    print(fitness)\n",
    "\n",
    "    # Selecting the best parents in the population for mating.\n",
    "    parents = select_mating_pool(new_population, fitness, \n",
    "                                      num_parents_mating)\n",
    "    \n",
    "    # print(parents)\n",
    "\n",
    "    # Generating next generation using crossover.\n",
    "    offspring_crossover = crossover_2(parents,\n",
    "                                       offspring_size=(pop_size[0]-parents.shape[0], col_len))\n",
    "\n",
    "\n",
    "    # Adding some variations to the offsrping using mutation.\n",
    "    offspring_mutation = enhanced_mutation(offspring_crossover)\n",
    "\n",
    "    # print(offspring_mutation)\n",
    "\n",
    "    # Creating the new population based on the parents and offspring.\n",
    "    new_population[0:parents.shape[0], :] = parents\n",
    "    new_population[parents.shape[0]:, :] = offspring_mutation  # should be offspring_mutation\n",
    "\n",
    "    # The best result in the current iteration.\n",
    "    print(\"Generation : \", generation)\n",
    "    # print(offspring_crossover)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution fitness :  0.8013333333333333\n"
     ]
    }
   ],
   "source": [
    "# Getting the best solution after iterating finishing all generations.\n",
    "#At first, the fitness is calculated for each solution in the final generation.\n",
    "fitness = cal_pop_fitness(new_population, X_train, y_train, X_test,y_test)\n",
    "# Then return the index of that solution corresponding to the best fitness.\n",
    "best_match_idx = np.where(fitness == np.max(fitness))\n",
    "\n",
    "# print(\"Best solution : \", new_population[best_match_idx, :])\n",
    "print(\"Best solution fitness : \", fitness[best_match_idx[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution :  [[[644 484 244 211 131 296 453 391 518 350 213 334 362 401 354 432 514\n",
      "   460 155 539 427 424 317   1  46 342 347 517]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best solution : \", new_population[best_match_idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9667619047619047\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = new_population[best_match_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([644, 484, 244, 211, 131, 296, 453, 391, 518, 350, 213, 334, 362,\n",
       "       401, 354, 432, 514, 460, 155, 539, 427, 424, 317,   1,  46, 342,\n",
       "       347, 517])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8984285714285715\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train.iloc[:,feat[0][0]], y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test.iloc[:,feat[0][0]])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9228571428571428\n"
     ]
    }
   ],
   "source": [
    "new_population = [239 459 392 521 604 550 241 371 490 298 488 350 576 348 149 346 427 465\n",
    " 408 475 547  48 184 365 714 526 297 264]\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train.iloc[:,new_population], y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test.iloc[:,new_population])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      2058\n",
      "           1       0.97      0.98      0.97      2364\n",
      "           2       0.91      0.92      0.92      2133\n",
      "           3       0.91      0.90      0.91      2176\n",
      "           4       0.93      0.92      0.92      1936\n",
      "           5       0.90      0.90      0.90      1915\n",
      "           6       0.94      0.96      0.95      2088\n",
      "           7       0.93      0.93      0.93      2248\n",
      "           8       0.89      0.86      0.87      1992\n",
      "           9       0.88      0.90      0.89      2090\n",
      "\n",
      "    accuracy                           0.92     21000\n",
      "   macro avg       0.92      0.92      0.92     21000\n",
      "weighted avg       0.92      0.92      0.92     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# # fetch dataset \n",
    "# optical_recognition_of_handwritten_digits = fetch_ucirepo(id=80) \n",
    "  \n",
    "# # data (as pandas dataframes) \n",
    "# X = optical_recognition_of_handwritten_digits.data.features \n",
    "# y = optical_recognition_of_handwritten_digits.data.targets \n",
    "  \n",
    "# # metadata \n",
    "# print(optical_recognition_of_handwritten_digits.metadata) \n",
    "\n",
    "# # variable information \n",
    "# print(optical_recognition_of_handwritten_digits.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y= y.to_numpy()\n",
    "# y =y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "# svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_classifier = xgb.XGBClassifier()\n",
    "# xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_pop_fitness(pop, X_train, y_train, X_test, y_test):\n",
    "    fitness = []\n",
    "    for i in range(len(pop)):\n",
    "        columns = np.unique(pop[i])\n",
    "        \n",
    "        X_train_ind = X_train.iloc[:,columns]\n",
    "        rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf_classifier.fit(X_train_ind, y_train)\n",
    "\n",
    "        y_pred = rf_classifier.predict(X_test.iloc[:,columns])\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        fitness.append(accuracy)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def fit_svm(pop, X_train, y_train, X_test, y_test):\n",
    "    fitness = []\n",
    "    for i in range(len(pop)):\n",
    "        columns = np.unique(pop[i])\n",
    "        \n",
    "        X_train_ind = X_train.iloc[:, columns]\n",
    "        svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "        svm_classifier.fit(X_train_ind, y_train)\n",
    "\n",
    "        y_pred = svm_classifier.predict(X_test.iloc[:, columns])\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        fitness.append(accuracy)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def fit_xgboost(pop, X_train, y_train, X_test, y_test):\n",
    "    fitness = []\n",
    "    for i in range(len(pop)):\n",
    "        columns = np.unique(pop[i])\n",
    "        \n",
    "        X_train_ind = X_train.iloc[:, columns]\n",
    "        xgb_classifier = xgb.XGBClassifier()\n",
    "        xgb_classifier.fit(X_train_ind, y_train)\n",
    "\n",
    "        y_pred = xgb_classifier.predict(X_test.iloc[:, columns])\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        fitness.append(accuracy)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "def select_mating_pool(pop, fitness, num_parents):\n",
    "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
    "    parents = np.empty((num_parents, pop.shape[1]))\n",
    "    for parent_num in range(num_parents):\n",
    "        max_fitness_idx = np.where(fitness == np.max(fitness))\n",
    "        max_fitness_idx = max_fitness_idx[0][0]\n",
    "        parents[parent_num, :] = pop[max_fitness_idx, :]\n",
    "        fitness[max_fitness_idx] = -1\n",
    "    return parents\n",
    "\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = np.empty(offspring_size)\n",
    "\n",
    "    for k in range(offspring_size[0]):\n",
    "        # Always perform one-point crossover.\n",
    "        crossover_point = np.random.randint(1, parents.shape[1])\n",
    "        parent1_idx = k % parents.shape[0]\n",
    "        parent2_idx = (k + 1) % parents.shape[0]\n",
    "        offspring[k, :crossover_point] = parents[parent1_idx, :crossover_point]\n",
    "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "\n",
    "    return offspring\n",
    "\n",
    "def mutation(offspring_crossover):\n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    for idx in range(offspring_crossover.shape[0]):\n",
    "        # The random value to be added to the gene.\n",
    "        random_value = np.random.choice([-1, 0, 1], 1)\n",
    "        offspring_crossover[idx, 4] = offspring_crossover[idx, 4] + random_value\n",
    "    return offspring_crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[415 268 472 ... 349 294 439]\n",
      " [469 531 461 ... 400 455 589]\n",
      " [454 423 373 ... 313 472 144]\n",
      " ...\n",
      " [652 353 417 ... 106 525 311]\n",
      " [479 237 478 ... 336 640 314]\n",
      " [400 320 409 ... 420  96 207]]\n"
     ]
    }
   ],
   "source": [
    "col_len = 112\n",
    "\n",
    "sol_per_pop = 100\n",
    "num_parents_mating = 50\n",
    "\n",
    "pop_size = (sol_per_pop,col_len)\n",
    "\n",
    "max_value = 783 \n",
    "std_dev = 150\n",
    "mean = max_value / 2\n",
    "\n",
    "new_population = np.random.normal(mean, std_dev, pop_size).astype(int)\n",
    "\n",
    "new_population[new_population > max_value] = max_value\n",
    "new_population[new_population < 0] = 0\n",
    "\n",
    "print(new_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train = X_train[:10000]\n",
    "X_test = X_test[:3000]\n",
    "y_train = y_train[:10000]\n",
    "y_test = y_test[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_generations = 20\n",
    "for generation in range(num_generations):\n",
    "    # Measing the fitness of each chromosome in the population.\n",
    "    fitness = cal_pop_fitness(new_population, X_train,y_train,X_test,y_test)\n",
    "\n",
    "    print(fitness)\n",
    "\n",
    "    # Selecting the best parents in the population for mating.\n",
    "    parents = select_mating_pool(new_population, fitness, \n",
    "                                      num_parents_mating)\n",
    "    \n",
    "    # print(parents)\n",
    "\n",
    "    # Generating next generation using crossover.\n",
    "    offspring_crossover = crossover(parents,\n",
    "                                       offspring_size=(pop_size[0]-parents.shape[0], col_len))\n",
    "\n",
    "\n",
    "    # Adding some variations to the offsrping using mutation.\n",
    "    offspring_mutation = mutation(offspring_crossover)\n",
    "\n",
    "    # print(offspring_mutation)\n",
    "\n",
    "    # Creating the new population based on the parents and offspring.\n",
    "    new_population[0:parents.shape[0], :] = parents\n",
    "    new_population[parents.shape[0]:, :] = offspring_mutation  # should be offspring_mutation\n",
    "\n",
    "    # The best result in the current iteration.\n",
    "    if generation%10 ==0:\n",
    "        print(\"Generation : \", generation)\n",
    "        # print(offspring_crossover)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution fitness :  0.933\n"
     ]
    }
   ],
   "source": [
    "# Getting the best solution after iterating finishing all generations.\n",
    "#At first, the fitness is calculated for each solution in the final generation.\n",
    "fitness = cal_pop_fitness(new_population, X_train, y_train, X_test,y_test)\n",
    "# Then return the index of that solution corresponding to the best fitness.\n",
    "best_match_idx = np.where(fitness == np.max(fitness))\n",
    "\n",
    "# print(\"Best solution : \", new_population[best_match_idx, :])\n",
    "print(\"Best solution fitness : \", fitness[best_match_idx[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution :  [[[457 603 536 553  55 432 653 378 304 635 698 275 265 260 539 210 260\n",
      "   519 238 308 187 267 305 368 525 434 454 689 217 492 539 349 185 345\n",
      "   577 129 443 417 665 339 628 265 313 281 375 319 313 565 283 577 516\n",
      "   430 593 334 525 287 354 460 409 470 622 417 425 309 307 600 276 475\n",
      "   216 269 414 210 479 290 474 300 576 374  14 272 336 337 463 256 526\n",
      "   236 359 348 467 342 324 217 350 333 567 277 553 352 421 438 233 231\n",
      "   370 487 521 270 485 551 355 409 460 221]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best solution : \", new_population[best_match_idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9667619047619047\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = new_population[best_match_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([457, 603, 536, 553,  55, 432, 653, 378, 304, 635, 698, 275, 265,\n",
       "       260, 539, 210, 260, 519, 238, 308, 187, 267, 305, 368, 525, 434,\n",
       "       454, 689, 217, 492, 539, 349, 185, 345, 577, 129, 443, 417, 665,\n",
       "       339, 628, 265, 313, 281, 375, 319, 313, 565, 283, 577, 516, 430,\n",
       "       593, 334, 525, 287, 354, 460, 409, 470, 622, 417, 425, 309, 307,\n",
       "       600, 276, 475, 216, 269, 414, 210, 479, 290, 474, 300, 576, 374,\n",
       "        14, 272, 336, 337, 463, 256, 526, 236, 359, 348, 467, 342, 324,\n",
       "       217, 350, 333, 567, 277, 553, 352, 421, 438, 233, 231, 370, 487,\n",
       "       521, 270, 485, 551, 355, 409, 460, 221])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9505714285714286\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train.iloc[:,feat[0][0]], y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test.iloc[:,feat[0][0]])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.32528814895085"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9505714285714286/0.96676190476190470 * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

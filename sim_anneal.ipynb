{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist.data, mnist.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(features):\n",
    "    X_train_subset = X_train.iloc[:, features]\n",
    "    X_test_subset = X_test.iloc[:, features]\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=5, random_state=42)\n",
    "    clf.fit(X_train_subset, y_train)\n",
    "    y_pred = clf.predict(X_test_subset)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return acc\n",
    "\n",
    "# Simulated Annealing\n",
    "def simulated_annealing(n_features, max_iterations=1000, initial_temperature=1.0, cooling_rate=0.95):\n",
    "    current_solution = np.random.choice(X.shape[1], n_features, replace=False)\n",
    "    current_score = objective(current_solution)\n",
    "\n",
    "    best_solution = np.copy(current_solution)\n",
    "    best_score = current_score\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "\n",
    "        if iteration % 10 == 0:\n",
    "            print(best_score)\n",
    "\n",
    "        temperature = initial_temperature * cooling_rate**iteration\n",
    "\n",
    "        # Propose a new solution by randomly changing one feature\n",
    "        new_solution = np.copy(current_solution)\n",
    "        index_to_change = np.random.randint(0, n_features)\n",
    "        new_feature = np.random.randint(0, X.shape[1])\n",
    "        while new_feature in new_solution:\n",
    "            new_feature = np.random.randint(0, X.shape[1])\n",
    "        new_solution[index_to_change] = new_feature\n",
    "\n",
    "        # Calculate the objective function value for the new solution\n",
    "        new_score = objective(new_solution)\n",
    "\n",
    "        # Accept the new solution if it's better or with a certain probability if it's worse\n",
    "        if new_score > current_score or np.random.rand() < np.exp((new_score - current_score) / temperature):\n",
    "            current_solution = np.copy(new_solution)\n",
    "            current_score = new_score\n",
    "\n",
    "        # Update the best solution if needed\n",
    "        if current_score > best_score:\n",
    "            best_solution = np.copy(current_solution)\n",
    "            best_score = current_score\n",
    "\n",
    "    return best_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6118095238095238\n",
      "0.6118095238095238\n",
      "0.6118095238095238\n",
      "0.6395714285714286\n",
      "0.6921904761904762\n",
      "0.696\n",
      "0.696\n",
      "0.696\n",
      "0.696\n",
      "0.7131428571428572\n",
      "0.7634761904761905\n",
      "0.7661428571428571\n",
      "0.7891904761904762\n",
      "0.7891904761904762\n",
      "0.7923333333333333\n",
      "0.7941904761904762\n",
      "0.8066190476190476\n",
      "0.8066190476190476\n",
      "0.8092380952380952\n",
      "0.8143333333333334\n",
      "0.8173809523809524\n",
      "0.8232857142857143\n",
      "0.8277142857142857\n",
      "0.8288571428571428\n",
      "0.8316666666666667\n",
      "0.8358571428571429\n",
      "0.8358571428571429\n",
      "0.8411904761904762\n",
      "0.8411904761904762\n",
      "0.8411904761904762\n",
      "0.8414285714285714\n",
      "0.8493809523809523\n",
      "0.8510952380952381\n",
      "0.852047619047619\n",
      "0.852047619047619\n",
      "0.8570476190476191\n",
      "0.8594285714285714\n",
      "0.8602857142857143\n",
      "0.8602857142857143\n",
      "0.8621904761904762\n",
      "0.8621904761904762\n",
      "0.8645238095238095\n",
      "0.8645238095238095\n",
      "0.8645238095238095\n",
      "0.8645238095238095\n",
      "0.8645238095238095\n",
      "0.8645238095238095\n",
      "0.8664285714285714\n",
      "0.8664285714285714\n",
      "0.8681428571428571\n",
      "0.8681428571428571\n",
      "0.8681428571428571\n",
      "0.8681428571428571\n",
      "0.8681428571428571\n",
      "0.8681428571428571\n",
      "0.8681428571428571\n",
      "0.8681428571428571\n",
      "0.8681428571428571\n",
      "0.8681428571428571\n",
      "0.8681428571428571\n",
      "0.8681428571428571\n",
      "0.8681428571428571\n",
      "0.8681428571428571\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8699523809523809\n",
      "0.8702857142857143\n",
      "0.8702857142857143\n",
      "0.8712857142857143\n",
      "0.8712857142857143\n",
      "0.8723333333333333\n",
      "0.8723333333333333\n",
      "0.8723333333333333\n",
      "0.8723333333333333\n",
      "0.8723333333333333\n",
      "0.8723333333333333\n",
      "0.8723333333333333\n",
      "0.8723333333333333\n",
      "0.8723333333333333\n",
      "0.8723333333333333\n",
      "0.8723333333333333\n",
      "0.8723333333333333\n",
      "0.8723333333333333\n",
      "Selected Features: [432 318 327 484 184 182 353 372 434 625 265 515 350 481 518 656 237 241\n",
      " 595 289 244 130 154 439 541 321 324 149]\n"
     ]
    }
   ],
   "source": [
    "# Set the number of features to select\n",
    "n_feature = 28\n",
    "\n",
    "# Run simulated annealing\n",
    "selected_features = simulated_annealing(n_feature)\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset = X_train.iloc[:, selected_features]\n",
    "X_test_subset = X_test.iloc[:, selected_features]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_subset, y_train)\n",
    "y_pred = clf.predict(X_test_subset)\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9228571428571428\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[432 318 327 484 184 182 353 372 434 625 265 515 350 481 518 656 237 241\n",
      " 595 289 244 130 154 439 541 321 324 149]\n"
     ]
    }
   ],
   "source": [
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_solution = np.random.choice(X.shape[1], n_feature, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset = X_train.iloc[:, current_solution]\n",
    "X_test_subset = X_test.iloc[:, current_solution]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_subset, y_train)\n",
    "y_pred = clf.predict(X_test_subset)\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7179047619047619\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
